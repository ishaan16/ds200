{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of documents = 6362\n",
      "Average words per document = 118\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words += ['mr','would','say','lt', 'p', 'gt', 'amp', 'nbsp',\n",
    "               'bill','speaker','us','going','act','gentleman',\n",
    "              'gentlewoman','chairman','nay','yea','thank']\n",
    "pathnames = ['./convote_v1.1/data_stage_one/'+wor+'/' for \n",
    "             wor in ['development_set','training_set']]\n",
    "#pathnames = ['./data_stage_one/training_set/']\n",
    "docs,docLen=[],0\n",
    "for path in pathnames:\n",
    "    for filename in os.listdir(path):\n",
    "        with open(path+filename,'r') as inp:\n",
    "            f=inp.read()\n",
    "            words=word_tokenize(f)\n",
    "            words = [w.lower() for w in words]\n",
    "            noPunc = [w.translate(None,string.punctuation)\n",
    "                      for w in words]\n",
    "            noEmp = [w for w in noPunc if w.isalpha()]\n",
    "            noStop = [w for w in noEmp if not w\n",
    "                      in stop_words]\n",
    "            stemmed = [porter.stem(w) for w in noStop]\n",
    "            stemmed = [w for w in stemmed if not w\n",
    "                      in stop_words]\n",
    "        docLen+=len(stemmed)\n",
    "        docs.append(stemmed)\n",
    "        #docs.append(noStop)\n",
    "l = len(docs)\n",
    "print (\"Total Number of documents = %d\"%l)\n",
    "print(\"Average words per document = %d\"%(docLen/l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size = 15547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.021*\"iraq\" + 0.016*\"iraqi\" + 0.009*\"peopl\" + 0.009*\"year\" + 0.009*\"work\" + 0.007*\"forc\" + 0.007*\"resolut\" + 0.007*\"committe\" + 0.006*\"nation\" + 0.006*\"report\"'),\n",
       " (5,\n",
       "  u'0.016*\"energi\" + 0.012*\"oil\" + 0.010*\"ocean\" + 0.009*\"amend\" + 0.008*\"ga\" + 0.007*\"price\" + 0.007*\"time\" + 0.007*\"need\" + 0.006*\"year\" + 0.005*\"want\"'),\n",
       " (3,\n",
       "  u'0.011*\"fund\" + 0.010*\"budget\" + 0.009*\"year\" + 0.008*\"rule\" + 0.008*\"vote\" + 0.007*\"amend\" + 0.007*\"committe\" + 0.006*\"hous\" + 0.006*\"appropri\" + 0.006*\"resolut\"')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import tempfile\n",
    "TMP = tempfile.gettempdir()\n",
    "dcy = corpora.Dictionary(docs)\n",
    "print(\"Total vocabulary size = %d\"%len(dcy))\n",
    "dcy.save(os.path.join(TMP,'cong.dict'))\n",
    "corpus = [dcy.doc2bow(text) for text in docs]\n",
    "corpora.MmCorpus.serialize(os.path.join\n",
    "                           (TMP,'congCorp.mm'),corpus)\n",
    "#for c in corpus[:10]:\n",
    "#    print(c)\n",
    "tfidf = models.TfidfModel(corpus, normalize=True)\n",
    "tfidf_corpus = tfidf[corpus]\n",
    "tfidf_corpus = corpus\n",
    "lda = models.LdaModel(tfidf_corpus, id2word=dcy, \n",
    "                      num_topics=10)\n",
    "lda.print_topics(3,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.021*\"iraq\" + 0.016*\"iraqi\" + 0.009*\"peopl\" + 0.009*\"year\" + 0.009*\"work\" + 0.007*\"forc\" + 0.007*\"resolut\" + 0.007*\"committe\" + 0.006*\"nation\" + 0.006*\"report\" + 0.005*\"unit\" + 0.005*\"recommend\" + 0.005*\"support\" + 0.005*\"secur\" + 0.005*\"commiss\" + 0.005*\"new\" + 0.005*\"presid\" + 0.005*\"issu\" + 0.004*\"time\" + 0.004*\"hous\"'),\n",
       " (1,\n",
       "  u'0.025*\"tax\" + 0.012*\"plan\" + 0.011*\"cut\" + 0.009*\"benefit\" + 0.009*\"year\" + 0.009*\"billion\" + 0.008*\"deficit\" + 0.008*\"american\" + 0.008*\"republican\" + 0.008*\"pension\" + 0.006*\"worker\" + 0.006*\"peopl\" + 0.006*\"increas\" + 0.005*\"support\" + 0.005*\"famili\" + 0.005*\"today\" + 0.005*\"secur\" + 0.005*\"fund\" + 0.005*\"retir\" + 0.005*\"percent\"'),\n",
       " (2,\n",
       "  u'0.017*\"cut\" + 0.015*\"tax\" + 0.012*\"peopl\" + 0.011*\"health\" + 0.009*\"fund\" + 0.009*\"american\" + 0.009*\"million\" + 0.007*\"care\" + 0.007*\"program\" + 0.007*\"need\" + 0.007*\"increas\" + 0.006*\"year\" + 0.006*\"support\" + 0.006*\"percent\" + 0.006*\"provid\" + 0.006*\"dividend\" + 0.006*\"plan\" + 0.005*\"work\" + 0.005*\"children\" + 0.005*\"educ\"'),\n",
       " (3,\n",
       "  u'0.011*\"fund\" + 0.010*\"budget\" + 0.009*\"year\" + 0.008*\"rule\" + 0.008*\"vote\" + 0.007*\"amend\" + 0.007*\"committe\" + 0.006*\"hous\" + 0.006*\"appropri\" + 0.006*\"resolut\" + 0.006*\"demand\" + 0.006*\"state\" + 0.005*\"program\" + 0.005*\"saver\" + 0.005*\"provid\" + 0.005*\"time\" + 0.005*\"make\" + 0.005*\"million\" + 0.004*\"spend\" + 0.004*\"ask\"'),\n",
       " (4,\n",
       "  u'0.011*\"peopl\" + 0.011*\"know\" + 0.009*\"time\" + 0.008*\"amend\" + 0.008*\"think\" + 0.007*\"want\" + 0.007*\"get\" + 0.007*\"make\" + 0.006*\"committe\" + 0.006*\"year\" + 0.005*\"need\" + 0.005*\"thing\" + 0.005*\"tax\" + 0.005*\"one\" + 0.005*\"today\" + 0.005*\"work\" + 0.005*\"vote\" + 0.004*\"right\" + 0.004*\"hous\" + 0.004*\"issu\"'),\n",
       " (5,\n",
       "  u'0.016*\"energi\" + 0.012*\"oil\" + 0.010*\"ocean\" + 0.009*\"amend\" + 0.008*\"ga\" + 0.007*\"price\" + 0.007*\"time\" + 0.007*\"need\" + 0.006*\"year\" + 0.005*\"want\" + 0.005*\"nation\" + 0.005*\"fuel\" + 0.005*\"state\" + 0.005*\"get\" + 0.004*\"one\" + 0.004*\"new\" + 0.004*\"gasolin\" + 0.004*\"refineri\" + 0.004*\"increas\" + 0.004*\"make\"'),\n",
       " (6,\n",
       "  u'0.052*\"yield\" + 0.027*\"minut\" + 0.023*\"time\" + 0.011*\"committe\" + 0.009*\"member\" + 0.009*\"balanc\" + 0.008*\"may\" + 0.008*\"madam\" + 0.007*\"state\" + 0.007*\"way\" + 0.007*\"distinguish\" + 0.006*\"amend\" + 0.006*\"trade\" + 0.006*\"consum\" + 0.005*\"california\" + 0.005*\"want\" + 0.005*\"mean\" + 0.005*\"vote\" + 0.005*\"back\" + 0.005*\"new\"'),\n",
       " (7,\n",
       "  u'0.035*\"pension\" + 0.016*\"plan\" + 0.012*\"compani\" + 0.010*\"benefit\" + 0.010*\"worker\" + 0.009*\"airlin\" + 0.008*\"employe\" + 0.008*\"time\" + 0.007*\"american\" + 0.006*\"make\" + 0.006*\"protect\" + 0.006*\"year\" + 0.006*\"retir\" + 0.005*\"work\" + 0.005*\"peopl\" + 0.005*\"support\" + 0.005*\"industri\" + 0.005*\"employ\" + 0.005*\"legisl\" + 0.004*\"busi\"'),\n",
       " (8,\n",
       "  u'0.013*\"state\" + 0.008*\"nation\" + 0.005*\"amend\" + 0.005*\"hous\" + 0.005*\"feder\" + 0.005*\"year\" + 0.005*\"support\" + 0.005*\"need\" + 0.005*\"ocean\" + 0.005*\"time\" + 0.005*\"unit\" + 0.005*\"also\" + 0.004*\"commiss\" + 0.004*\"fund\" + 0.004*\"forc\" + 0.004*\"protect\" + 0.004*\"provid\" + 0.004*\"one\" + 0.004*\"new\" + 0.004*\"committe\"'),\n",
       " (9,\n",
       "  u'0.016*\"hous\" + 0.014*\"committe\" + 0.011*\"rule\" + 0.009*\"member\" + 0.008*\"vote\" + 0.008*\"legisl\" + 0.007*\"amend\" + 0.007*\"peopl\" + 0.006*\"protect\" + 0.006*\"want\" + 0.006*\"time\" + 0.006*\"debat\" + 0.006*\"one\" + 0.006*\"state\" + 0.005*\"congress\" + 0.005*\"make\" + 0.005*\"right\" + 0.005*\"report\" + 0.005*\"resolut\" + 0.004*\"democrat\"')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(-1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
